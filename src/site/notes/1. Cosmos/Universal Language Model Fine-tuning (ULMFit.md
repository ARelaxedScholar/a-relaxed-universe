---
{"dg-publish":true,"permalink":"/1-cosmos/universal-language-model-fine-tuning-ulm-fit/"}
---


202405032345
Status: #idea
Tags: [[Natural Language Processing (NLP)\|Natural Language Processing (NLP)]]
# Universal Language Model Fine-tuning (ULMFit
This is brilliant technique that consists in fine-tuning a pretrained language model say [[BERT\|BERT]] on a dataset related to the task that you want to make it do, before actually training it for the task. 

As a result the model is able to see more data, and the results are significantly better.
## References
[[2. White Holes/References/Practical Deep Learning for Coders#Chapter 10\|Practical Deep Learning for Coders#Chapter 10]]


